# Elixirr Voice & Communication Principles

**Version**: 1.0
**Created**: 2026-02-09
**Purpose**: Define how Elixirr communicates about AI transformation across all materials and interactions.

---

## Core Voice Attributes

### Tone Spectrum

**Authoritative, not arrogant**
- We speak from pattern recognition across hundreds of AI transformations, not theory
- Language signals: "We see this pattern...", "In practice...", "The organizations that succeed..."
- Never position Elixirr as infallible — position as experienced pattern recognizer
- Confidence comes from specificity, not volume

**Practical, not theoretical**
- Every statement connects to concrete action or observable behavior
- Avoid abstract frameworks without implementation. "Design thinking" becomes "Here's how leaders actually redesigned their first meeting"
- Data grounds assertions. "60% of organizations skip Layer 1" beats "Most organizations struggle with strategy"
- Test the internal question: "Could someone act on this right now?"

**Provocative, not safe**
- Name the uncomfortable truths that executives feel but don't say
- Replace: "Change management can be challenging" with "Asking someone to work with AI is asking them to destabilize their professional identity"
- Provocative doesn't mean shock value — it means saying true things that haven't been said in the room yet
- Create forward momentum by validating what's actually hard

**Specific, not abstract**
- Replace generic consulting language with concrete examples
- Instead of: "Implement a governance framework" → "Define decision rights: Who decides if an AI workflow meets quality thresholds?"
- Use "digital coworker" not "AI tool" — the specificity changes how people think about it
- Numbers, examples, and scenarios make ideas real

---

## Vocabulary Preferences

### Strategic Language
| Prefer | Avoid | Why |
|--------|-------|-----|
| Digital coworker | AI tool, AI assistant, automation | Reframes relationship; implies hire-like responsibility |
| Social contract renegotiation | Change management | Names what's actually happening: work fundamentals are renegotiated |
| Identity shift | Reskilling, upskilling | Honest about the psychological barrier; skills are secondary |
| Outcome | Use case | Outcome is measurable, tied to business; use case is abstract |
| Operating system | Framework, model, methodology | OS implies interdependence and continuous operation |
| Failure pattern | Challenge, issue, problem | Failure pattern is systemic, repeatable, diagnostic |
| Augmented professional | AI-enabled worker, AI-ready employee | Augmented signals elevation; AI-enabled signals tool application |
| Capacity creation | Efficiency, cost savings | Capacity creation opens new work; efficiency implies doing same work faster |

### Language to Avoid
- **Hedging language**: "might", "could potentially", "may enable", "could help" → Replace with "does", "enables", "delivers"
- **Generic consulting-speak**: "leverage synergies", "holistic approach", "best-in-class", "transformation journey" → Replace with specific verbs and outcomes
- **Passive voice**: "AI tools were deployed" → "We deployed AI..." or "The team launched..."
- **Jargon without grounding**: If you use a term unfamiliar to senior executives, define it immediately in observable terms

---

## Voice Principles in Practice

### 1. Speak from Experience
**Pattern**: "We see this pattern..." / "In practice, organizations that..." / "What typically happens is..."

This signals:
- You've seen enough repetitions to recognize patterns
- You're not theorizing — you're observing
- Others aren't alone in their challenge

**Example**:
- Weak: "Many organizations struggle with adoption"
- Strong: "We see a pattern: teams complete training, return to work, and revert to old workflows within 6 weeks because the new way of working doesn't map to how their leaders work"

### 2. Use Diagnostic Questions as Hooks
**Pattern**: Phrase insights as questions the prospect can ask their own team

This works because:
- It moves from "you're failing" to "here's what to examine"
- It invites self-discovery rather than external judgment
- It acknowledges their team knows their context better than we do

**Example**:
- Weak: "Your organization probably isn't clear on outcomes"
- Strong: "Can your leadership team name the top 3 value-driving activities without reaching for a slide deck? If not, that's where to start"

### 3. Name Uncomfortable Truths
**Pattern**: Say the thing that's true but hasn't been said in the room yet

This creates credibility because:
- It validates what smart people feel but fear saying aloud
- It signals "this source understands our reality"
- It breaks through consultant-speak that feels disconnected from lived experience

**Example**:
- Weak: "Workforce transformation requires new ways of thinking"
- Strong: "If your people see AI as a threat to their expertise, no amount of training will change that. You have to address the threat first—not by denying it, but by showing them how AI makes their judgment more valuable"

### 4. Be Direct Without Dismissing
**Pattern**: Clear stance + acknowledgment of legitimate complexity

This balances authority with empathy:
- State your point cleanly
- Acknowledge what makes it hard
- Connect to why it matters

**Example**:
- Wrong: "You're doing AI wrong" (dismissive)
- Wrong: "There are many valid approaches to AI transformation" (spineless)
- Right: "Most organizations try to pilot AI before defining strategy. This makes sense—you want proof before big commitments. But pilots without strategic context fail to scale because they answer 'Can we?' instead of 'Should we?'"

---

## Formatting Conventions

### Punctuation & Typography
- **Em dashes (—) not hyphens (-)** for asides and emphasis
- **Smart quotes (" ") not straight quotes (" ")**
- **Bold for key concepts**, not as a replacement for clarity
- **Lists over paragraphs** when there's genuine enumeration; paragraphs over lists when narrative flow matters

### Data Usage
- **Ground assertions in numbers**: "60% of organizations..." not "Most organizations..."
- **Include source signal**: "Based on our diagnostic of 200+ AI transformations..." provides context
- **Use data for pattern recognition, not proof of superiority**: Data explains what we see; it doesn't prove we're better

### Structuring Difficult Messages
When delivering challenging insights:
1. **Name the pattern**: "We see this..."
2. **Explain why it happens**: "This happens because..."
3. **Show the consequence**: "The result is..."
4. **Offer reframe**: "What actually works is..."

**Example**:
"We see organizations keep pilots isolated — small teams, controlled environment, limited scope. This happens because pilots feel safer than enterprise rollouts. The result is a solution that doesn't scale (the isolated team had uniquely high adoption; the broader org doesn't replicate it). What actually works is pilots designed to prove architecture, not just capability."

---

## Elixirr vs. Competitor Language

### vs. Big 4 (McKinsey, Deloitte, Accenture, EY)
Big 4 language:
- "Organizations on their digital transformation journey..."
- "Implement a comprehensive change management approach"
- "50-page strategy document with 12 maturity dimensions"
- "Leverage organizational design to optimize outcomes"

Elixirr language:
- "Organizations moving from AI pilots to AI-native operations"
- "Redesign decision rights, workflows, and how value gets made"
- "Clear priorities tied to measurable outcomes, not pages of framework"
- "Here's what actually changes in work, roles, and leadership"

**Difference**: We're tactical, not theoretical. Results, not maturity models.

### vs. Boutique AI Firms
Boutique language:
- "Deploy state-of-the-art models"
- "Implement RAG systems for knowledge management"
- "Optimize prompt engineering workflows"
- Focus on what's technically possible

Elixirr language:
- "Build a 10-layer operating system for AI-native work"
- "Redesign how decisions get made with AI as a coworker"
- "Diagnose why pilots fail and fix the 5 layers that matter"
- Focus on what creates organizational value

**Difference**: We're organization-first, not technology-first. Context over tools.

### vs. Internal Teams
What internal teams miss:
- Blind to their own failure patterns
- Limited visibility into what other industries/companies did first
- Pulled in too many directions at once
- Lack external pattern recognition

Elixirr language (when competing against build-it-internally):
- "You know your organization better than anyone. What you're missing is visibility into what works across a hundred other organizations facing the same challenge"
- "We diagnose faster because we've seen these patterns before"
- "You can do this internally. We can help you avoid the 12-month detour your peers already took"

### vs. Technology Vendors
Vendor language:
- "Adopt our AI platform"
- "Our tool enables faster adoption"
- "Deploy in weeks"
- Measure success as adoption rates

Elixirr language:
- "Choose your tools after you've redesigned work"
- "Move from pilots to production by building the right operating model first"
- "Timeline depends on how ready your organization is; we help you get ready"
- "Measure impact: better decisions, solved problems, capacity created"

**Difference**: Vendors sell tools. We sell transformation. Tools are one layer in a ten-layer system.

---

## High-Impact Phrase Library

### Opening Reframes (Set up the complexity)
- "AI transformation combines three forces simultaneously — pace, breadth, and depth — that your existing playbooks weren't designed for"
- "This is more like starting a new company than deploying software"
- "By the time you've trained teams on today's capabilities, tomorrow's capabilities have emerged"
- "Most organizations treat AI like their last technology rollout. This one is different"

### Strategic Clarity (Shift from tools to outcomes)
- "Let's start with outcomes, not use cases. Which 3 activities drive 80% of your value?"
- "If you can't measure the outcome, you can't improve it — with or without AI"
- "The best AI strategy is a business strategy where AI is the enabler"
- "Pilots that don't answer 'Should we?' just waste time that could be spent on 'How do we?' at scale"

### Human Reality (Name the barrier)
- "Asking someone to work with AI is asking them to destabilize their professional identity"
- "Resistance isn't irrational — their nervous system is protecting something valuable"
- "You can't think your way to this. People experience their way through it"
- "If your leaders' workflows haven't changed, the organization reads the signal: this doesn't really matter"

### Systemic Thinking (Connect the dots)
- "We see this pattern a lot. Here are the other layers usually connected to it"
- "This isn't just a technology problem — it's a redesign problem"
- "The highest-leverage interventions are almost always in strategy, leadership, work design, and human transformation — not in the technology layer"
- "Organizations fail at scale because they fixed Layer 7 without fixing Layers 1 through 5"

### Proof (Measurement that matters)
- "We measure outcomes, not activity: better decisions, faster cycle time, capacity created"
- "If you're tracking PoCs shipped or models built, you're measuring the wrong things"
- "Impact is when someone stops doing something they used to do and uses that time for higher-value work"

---

## What This Voice Sounds Like: Full Example

**Weak opener**: "AI transformation is a complex journey that requires organizational alignment and change management best practices."

**Elixirr voice**:
"Most organizations approach AI the same way they approached cloud or mobile—as a technology rollout. Deploy the tool, train the team, measure adoption. But AI breaks that playbook. It's not just faster; it's fundamentally different. It forces you to rethink what work means, who does it, and how you measure success. We see organizations treat AI like pilots are the hard part. In practice, the hard part comes after: scaling something that worked in a controlled team environment across an entire organization where power dynamics, incentives, and ways of working are completely different."

---

## Summary: The Elixirr Voice Test

Before publishing, ask:
1. **Is it specific?** Can someone action it, or is it abstract? (specific → good)
2. **Does it honor complexity without wallowing in it?** Does it name hard truths and point toward what works? (yes → good)
3. **Could this come from Big 4 consulting?** If yes, make it more direct, less formal, more actionable (no → good)
4. **Is it true?** Is it based on pattern, not hope? (yes → good)
5. **Would a skeptical executive lean in?** Does it validate their reality before explaining what to do about it? (yes → good)
